{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc-iKFCjJSEd"
      },
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "import sklearn.ensemble\n",
        "import csv\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "#########\n",
        "#uploaded= files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjQKkv3co6xJ",
        "outputId": "0dc7bcdd-32d3-455e-f053-e3b71f25f1c2"
      },
      "source": [
        "#These are linux commands to download data files. They will be saved in the current directory\n",
        "#Run these commands one time\n",
        "!wget https://github.com/ahmedmk323/CS301-Project/blob/master/csv/positive.review\n",
        "!wget https://github.com/ahmedmk323/CS301-Project/blob/master/csv/negative.review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-26 14:52:42--  https://github.com/ahmedmk323/CS301-Project/blob/master/csv/negative.review\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘negative.review.1’\n",
            "\n",
            "\rnegative.review.1       [<=>                 ]       0  --.-KB/s               \rnegative.review.1       [ <=>                ] 104.85K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-04-26 14:52:42 (4.79 MB/s) - ‘negative.review.1’ saved [107369]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkmYLB1krfLv"
      },
      "source": [
        "# Data Extarction Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-muL3yJ2YkN8"
      },
      "source": [
        "features=[\"review\",\"unique_id\",\"unique_num\"\"rating\",\"title\", \"review_text\",\"class_\"]\n",
        "def data_extraction(f_name, c): #c is an int that identfies the class value 0 or 1\n",
        "  file= open(f_name, 'r', encoding='latin-1')\n",
        "  reader= csv.reader(file,delimiter='\\n')\n",
        "  lst= []\n",
        "  buffer=\"\"\n",
        "  flag= False\n",
        "  index=-1\n",
        "  for row in reader:\n",
        "    if (row == []):\n",
        "      continue\n",
        "    slash= row[0][1:2] #To check whether slash exists or not\n",
        "    strip_w= row[0].strip(\"<>\")\n",
        "    \n",
        "    if (slash == '/' and ((strip_w.strip('/')) in features)):\n",
        "      if ((strip_w) ==\"/review\"):\n",
        "        lst[index].append(c)\n",
        "\n",
        "      if (buffer != '' and (buffer not in lst[index])):\n",
        "        lst[index].append(buffer)\n",
        "      buffer=\"\"\n",
        "      flag= False\n",
        "      continue\n",
        "    if (strip_w == \"review\"):\n",
        "      index+=1\n",
        "      lst.append([])\n",
        "    elif (strip_w in features):\n",
        "      flag=True\n",
        "      buffer=\"\"\n",
        "      continue\n",
        "    if (flag):\n",
        "      buffer+= row[0]\n",
        "  return lst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyL5kZrwyPsf"
      },
      "source": [
        "  \n",
        " #positvie.REVIEW raw data file\n",
        " # negative.REVIEW raw data file\n",
        "p_data= data_extraction('./positive.review', 1) \n",
        "n_data= data_extraction('./negative.review', 0)\n",
        "\n",
        "df0=pd.DataFrame(p_data,columns=(features[1::])) #Dataframe 1 to load positve reviews data\n",
        "df1=pd.DataFrame(n_data,columns=(features[1::])) #Dataframe 2 to load negative reviews data\n",
        "frames=[df0,df1]\n",
        "main_df=pd.concat(frames) #Merging the two dataframes  \n",
        "main_df= main_df.dropna() #Dropping rows that cointain Nan values\n",
        "main_df= main_df.sample(frac=1) #Randomizing rows in the dataframe\n",
        "\n",
        "X=main_df.review_text\n",
        "y=main_df.class_\n",
        "\n",
        "X_train, X_test, y_train,y_test= train_test_split(X,y, test_size=0.2) #splitting training and test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lODcR5wV6ipQ"
      },
      "source": [
        "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
        "train_vectors = vectorizer.fit_transform(X_train)\n",
        "test_vectors = vectorizer.transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mAQ2Fz4NLt4"
      },
      "source": [
        "# USING RANDOM FOREST CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEqtRhfLNFbw",
        "outputId": "f4ddf8ac-b0d1-40cd-a699-9b22fd20a759"
      },
      "source": [
        "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
        "rf.fit(train_vectors,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FYjcnwmOLhx",
        "outputId": "2a740bd8-bebe-428f-c71c-2b8d4658921a"
      },
      "source": [
        "pred = rf.predict(test_vectors)\n",
        "sklearn.metrics.f1_score(y_test, pred, average='binary')\n",
        "print(sklearn.metrics.classification_report(np.rint(pred),y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.66      0.75       116\n",
            "         1.0       0.58      0.85      0.69        65\n",
            "\n",
            "    accuracy                           0.72       181\n",
            "   macro avg       0.73      0.75      0.72       181\n",
            "weighted avg       0.77      0.72      0.73       181\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}